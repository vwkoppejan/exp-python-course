{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment goals:\n",
    "+ practice creating custom transformers and estimators\n",
    "+ practice performing grid search\n",
    "+ build custom pipelines\n",
    "+ solidify git knowledge and practice working together effectively\n",
    "+ make a first attempt to productionizing ML model\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this lab we will be using [car sales dataset](https://www.kaggle.com/orgesleka/used-cars-database) from Kaggle. I know - everybody is sick of predicting car prices by now, but cars happen to have a good mix of numerical and categorical features and that's just what we need for this exercise.\n",
    "\n",
    "**Remember**, the  main objective of this assignment is not to train the most accurate model, but to practice building custom blocks of estimators and transformers. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by downloading the dataset and doing a quick exploration.\n",
    "- which features are categorical and which are numerical?\n",
    "- are there lots of missing values?\n",
    "- which column contains the dependent variable?\n",
    "\n",
    "For the sake of simplicity we will consider that each row contains a separate listing so we can treat index as our id variable. We will only focus on private sellers (`seller=='privat'`) and offerType equal to \"Angebot\". Also to keep it somewhat scoped we will only use the following features:\n",
    "- brand\n",
    "- gearbox\n",
    "- power PS\n",
    "- kilometer\n",
    "- vehicle age (needs to be constructed based on year of registration and date of ad placement)\n",
    "- fuelType\t\n",
    "- model (optional)\n",
    "- notRepairedDamage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Excercise 1**\n",
    ">\n",
    "> Load dataset into pandas dataframe, select only specified rows, add age column, select specified columns and create a train and test split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical transformer\n",
    "\n",
    "We have a number of categorical columns that we need to convert to numerical values in order to use them in our machine learning model. \n",
    "\n",
    "> **Excercise 2**\n",
    ">\n",
    "> Create a transformer that one-hot-encodes categorical columns from a `DataFrame`. The transformer should also be able to transform new, unseen data. Consider what you want to do with missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to preprocess numerical columns. Luckily for us this particular data extract has no missing values in numerical columns. But if we want to cover our bases and ensure that the pipeline also works on unseen data it might be a good idea to think about imputation strategy. On the other hand this strategy might be something we would want to include in our hyperparameter search.\n",
    "Depending on our future model choice we also need to scale our data. Good first option is to use a StandardScaler from sklearn. \n",
    "\n",
    "> **Excercise 3**\n",
    ">\n",
    "> Create a mini pipeline for numerical columns that implements a Simple Imputer with \"mean\" imputation strategy followed by a StandardScaler.\n",
    ">\n",
    "> If you have time and feeling exceptionally empowered, implement your own StandardScaler transformer which returns a pandas DataFrame (scikit-learn StandardScaler will return a numpy array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer 3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have preprocessed data that can be passed to a machine learning algorithm. `sklearn` comes with a varied suite of regression and classification models you can use. For this particular excercise you'll need to implement your own estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Excercise 4**\n",
    ">\n",
    "> Implement the most simple version of a Ridge regression that takes a single hyperparameter `alpha`. Don't go overboard with implementing your own matrix inverses, use `numpy`'s `linalg` module for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Excercise 4**\n",
    ">\n",
    "> Create a model pipeline that consists of ColumnTransformer for preprocessing the data and RidgeRegression for fitting the model\n",
    ">\n",
    "> Perform a grid search over your whole pipeline and visualize the results. \n",
    "Right now your pipeline does not have a whole lot of parameters to search over, you have an `alpha` in the RidgeRegression and you can also play with an imputation strategy. If you have time and energy left you can try adding other preprocessing steps (polynomial features, different scalers, ...?) or a different ML model. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Answer 4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have all components of your model building pipeline you can put them in a python package.\n",
    "\n",
    "Make sure that your package:\n",
    "- can be run from the command line\n",
    "- can run when the data is stored on a different location\n",
    "- can be run with varying parameter grid\n",
    "- should store a fitted and serialized model pipeline to a location you specify\n",
    "- has a minimal test suite\n",
    "- is well documented"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:trainings] *",
   "language": "python",
   "name": "conda-env-trainings-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
